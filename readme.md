# ğŸ™ï¸ Sriram Voice Assistant ğŸ¤– â€“ RAG-Based Voice Bot with PDF/Info Retrieval

This is a voice-based assistant powered by **OpenAI**, **FAISS vector database**, and a beautiful **React + Tailwind** frontend. It allows users to speak naturally, sends the audio to a backend, transcribes it, searches over personal documents, and responds back with generated answers â€“ as voice!

---

## ğŸ›  Tech Stack ğŸ‘¨â€ğŸ’»

**Frontend:** React.js, Tailwind CSS, Framer Motion, Axios  
**Backend:** FastAPI, OpenAI, FAISS, Python  
**Audio:** Whisper/OpenAI Speech-to-Text, gTTS / OpenAI Text-to-Speech  
**RAG (Retrieval-Augmented Generation):** FAISS + OpenAI Embeddings

---

## Wanna Clone It ğŸ–¨ï¸

**1. Clone the Project via Link**
[Follow this](https://github.com/ksriramreddy/MyVoiceAssitance.git)

**2. Follow the Folder Structure Below ğŸ‘‡ğŸ‘‡**
[Follow this](https://github.com/ksriramreddy/MyVoiceAssitance.git)
---

## ğŸ“‚ Folder Structure

```bash

#This are the file you need to update in order to make your OWN AI ASSISTANT

MyVoiceAssistant/
â”‚
â”œâ”€â”€ frontend/                # React client
â”‚   â””â”€â”€ src/pages/Home.jsx   # Main voice assistant UI
â”‚   â””â”€â”€.env                  # You backend deployed server link or localhost:8000/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ ask_bot.py       # RAG + LLM logic
â”‚   â”‚   â”œâ”€â”€ audio_utils.py   # Audio handling (TTS/STT)
â”‚   â”‚   â””â”€â”€ vectordb.py      # Embedding + FAISS index builder
â”‚   â”œâ”€â”€ vector_database/
â”‚   â”‚   â”œâ”€â”€ faiss.index      # FAISS index file
â”‚   â”‚   â””â”€â”€ docs.pkl         # Chunked documents for search
â”‚   â”œâ”€â”€ data/                # Place your PDF or text files here
â”‚   â”œâ”€â”€ main.py              # FastAPI main server
â”‚   â””â”€â”€ .env                 # Add your OpenAI API key here
```

**3. Code Updates âœï¸ğŸ“**

*3.1* Change the information in the `backend/data` you can add more text file.

*3.2* Run the `backend/app/vectordb.py` to ubdate the `fAISS` indices

*3.3* Make sure to add you `OPEN AI` API key in the `.env` file as `OPENAI_API_KEY`

*3.4* Add `VITE_BACKEND_API  = http://localhost:800` in `frontend/.env`

**4. Test Run ğŸ§‘â€ğŸ”¬ğŸ§ª**

``` bash


#for backend 
#open new terminal
cd backend
python -m venv new_env #create an new virtual env
pip install -r reqirements.txt #install all required packages
uvicorn main:app --reload # Run the backend Server

#for Frontend
#open new terminal

cd frontend
npm install # install all dependencies
npm run dev #start the server

```

**5. DeployğŸš€**

*5.1* User any service provider like `vercel` or `render` to deploy you voice assistance

*5.2* If your deploying individually make sure to ass your backend api to your frontend

**6. Facing Trouble âŒ**

Mail me here `k.sriramreddy9@gmail.com`
[LinkedIn](https://www.linkedin.com/in/sriram-reddy-34905a212/)
[Instagram](https://www.instagram.com/kothireddysriram/)